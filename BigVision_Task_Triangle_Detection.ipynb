{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XY5AEIuESgPF"
   },
   "outputs": [],
   "source": [
    "# %% Colab Setup and Environment Preparation\n",
    "%%capture\n",
    "!pip install ultralytics albumentations matplotlib seaborn opencv-python-headless scikit-learn --quiet\n",
    "!sudo apt-get install tree -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K4437_xMSlJe",
    "outputId": "306e73cc-2946-4c00-c9bf-72a4f4b60bc5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from google.colab import drive\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "os.environ['PYTHONHASHSEED'] = '42'\n",
    "\n",
    "# Mount Google Drive for model saving\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J1WflMu1S_Oj"
   },
   "outputs": [],
   "source": [
    "# %% Dataset Configuration - Optimized for T4 GPU\n",
    "class CFG:\n",
    "    # Directory structure\n",
    "    BASE_DIR = \"/content/triangle_dataset\"\n",
    "    IMAGE_DIR = os.path.join(BASE_DIR, \"images\")\n",
    "    LABEL_DIR = os.path.join(BASE_DIR, \"labels\")\n",
    "\n",
    "    # Dataset parameters\n",
    "    TOTAL_IMAGES = 1500  # (800 train, 350 val, 350 test)\n",
    "    IMG_SIZE = 640\n",
    "    TEST_SIZE = 0.23\n",
    "    VAL_SIZE = 0.23\n",
    "    NEGATIVE_RATIO = 0.2  # 20% images without triangles\n",
    "\n",
    "    # Image variety parameters\n",
    "    BG_TYPES = ['solid', 'gradient', 'noise', 'texture']\n",
    "    BG_PROBS = [0.25, 0.3, 0.25, 0.2]\n",
    "\n",
    "    # Triangle variety parameters\n",
    "    MIN_TRIANGLE_AREA = 900\n",
    "    MAX_TRIANGLES = 5\n",
    "    TRIANGLE_TYPES = ['regular', 'thin', 'obtuse', 'right']\n",
    "\n",
    "    # YOLO training\n",
    "    MODEL_TYPE = \"yolov8n.pt\"  # Using nano model for speed\n",
    "    EPOCHS = 100\n",
    "    BATCH = 16\n",
    "    PATIENCE = 20\n",
    "    WORKERS = 2\n",
    "\n",
    "    # Augmentation strengths\n",
    "    AUG_ROTATE_LIMIT = 45\n",
    "    AUG_SCALE_LIMIT = 0.2\n",
    "\n",
    "    SAVE_DIR = \"/content/drive/MyDrive/triangle_detection_rerun\"\n",
    "\n",
    "    # Visualizations\n",
    "    PLOT_METRICS = True\n",
    "    CONFUSION_MATRIX = True\n",
    "    TEST_SAMPLES = 8\n",
    "\n",
    "# Create directories\n",
    "for dir_path in [CFG.BASE_DIR, CFG.IMAGE_DIR, CFG.LABEL_DIR]:\n",
    "    os.makedirs(dir_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dQVaOOlITHf6"
   },
   "outputs": [],
   "source": [
    "# %% Enhanced Synthetic Dataset Generation\n",
    "def generate_background():\n",
    "    \"\"\"Create diverse backgrounds with 4 different types\"\"\"\n",
    "    bg_type = np.random.choice(CFG.BG_TYPES, p=CFG.BG_PROBS)\n",
    "    img = np.zeros((CFG.IMG_SIZE, CFG.IMG_SIZE, 3), dtype=np.uint8)\n",
    "\n",
    "    if bg_type == 'solid':\n",
    "        # Solid color with slight noise for realism\n",
    "        base_color = np.random.randint(0, 256, 3)\n",
    "        noise = np.random.randint(-20, 20, (CFG.IMG_SIZE, CFG.IMG_SIZE, 3))\n",
    "        img = np.clip(np.full((CFG.IMG_SIZE, CFG.IMG_SIZE, 3), base_color) + noise, 0, 255).astype(np.uint8)\n",
    "\n",
    "    elif bg_type == 'gradient':\n",
    "        if np.random.random() < 0.7:\n",
    "            angle = np.random.randint(0, 360)\n",
    "            c1, c2 = np.random.randint(0, 256, 3), np.random.randint(0, 256, 3)\n",
    "\n",
    "            y, x = np.mgrid[0:CFG.IMG_SIZE, 0:CFG.IMG_SIZE]\n",
    "            if angle < 90:\n",
    "                mask = (x + y) / (2 * CFG.IMG_SIZE)\n",
    "            elif angle < 180:\n",
    "                mask = (CFG.IMG_SIZE - x + y) / (2 * CFG.IMG_SIZE)\n",
    "            elif angle < 270:\n",
    "                mask = (CFG.IMG_SIZE - x + CFG.IMG_SIZE - y) / (2 * CFG.IMG_SIZE)\n",
    "            else:\n",
    "                mask = (x + CFG.IMG_SIZE - y) / (2 * CFG.IMG_SIZE)\n",
    "\n",
    "            for i in range(3):\n",
    "                img[:,:,i] = (c1[i] * (1 - mask) + c2[i] * mask).astype(np.uint8)\n",
    "\n",
    "        else:\n",
    "            c1, c2 = np.random.randint(0, 256, 3), np.random.randint(0, 256, 3)\n",
    "            center = (CFG.IMG_SIZE // 2, CFG.IMG_SIZE // 2)\n",
    "            y, x = np.mgrid[0:CFG.IMG_SIZE, 0:CFG.IMG_SIZE]\n",
    "\n",
    "            dist = np.sqrt((x - center[0])**2 + (y - center[1])**2)\n",
    "            max_dist = np.sqrt(2) * CFG.IMG_SIZE / 2\n",
    "            mask = np.clip(dist / max_dist, 0, 1)\n",
    "\n",
    "            for i in range(3):\n",
    "                img[:,:,i] = (c1[i] * (1 - mask) + c2[i] * mask).astype(np.uint8)\n",
    "\n",
    "    elif bg_type == 'noise':\n",
    "        noise_type = np.random.choice(['uniform', 'gaussian', 'salt_pepper'])\n",
    "\n",
    "        if noise_type == 'uniform':\n",
    "            img = np.random.randint(0, 256, (CFG.IMG_SIZE, CFG.IMG_SIZE, 3)).astype(np.uint8)\n",
    "\n",
    "        elif noise_type == 'gaussian':\n",
    "            mean = np.random.randint(0, 256)\n",
    "            std = np.random.randint(5, 60)\n",
    "            img = np.random.normal(mean, std, (CFG.IMG_SIZE, CFG.IMG_SIZE, 3))\n",
    "            img = np.clip(img, 0, 255).astype(np.uint8)\n",
    "\n",
    "        else:\n",
    "            img = np.random.randint(30, 200, (CFG.IMG_SIZE, CFG.IMG_SIZE, 3)).astype(np.uint8)\n",
    "            mask = np.random.random((CFG.IMG_SIZE, CFG.IMG_SIZE)) < 0.05\n",
    "            img[mask] = 255\n",
    "            mask = np.random.random((CFG.IMG_SIZE, CFG.IMG_SIZE)) < 0.05\n",
    "            img[mask] = 0\n",
    "\n",
    "    else:\n",
    "        texture_type = np.random.choice(['grid', 'checker', 'voronoi'])\n",
    "\n",
    "        if texture_type == 'grid':\n",
    "            grid_size = np.random.randint(20, 100)\n",
    "            color1 = np.random.randint(0, 256, 3)\n",
    "            color2 = np.random.randint(0, 256, 3)\n",
    "\n",
    "            x_grid = (np.arange(CFG.IMG_SIZE) // grid_size) % 2\n",
    "            y_grid = (np.arange(CFG.IMG_SIZE) // grid_size) % 2\n",
    "            grid = np.logical_xor.outer(x_grid, y_grid).astype(int)\n",
    "\n",
    "            for i in range(3):\n",
    "                img[:,:,i] = grid * color1[i] + (1 - grid) * color2[i]\n",
    "\n",
    "        elif texture_type == 'checker':\n",
    "            checker_size = np.random.randint(30, 120)\n",
    "            color1 = np.random.randint(0, 256, 3)\n",
    "            color2 = np.random.randint(0, 256, 3)\n",
    "\n",
    "            x_check = (np.arange(CFG.IMG_SIZE) // checker_size) % 2\n",
    "            y_check = (np.arange(CFG.IMG_SIZE) // checker_size) % 2\n",
    "            checker = np.logical_xor.outer(x_check, y_check).astype(int)\n",
    "\n",
    "            for i in range(3):\n",
    "                img[:,:,i] = checker * color1[i] + (1 - checker) * color2[i]\n",
    "\n",
    "        else:\n",
    "            num_centers = np.random.randint(5, 20)\n",
    "            centers = np.random.randint(0, CFG.IMG_SIZE, (num_centers, 2))\n",
    "            colors = np.random.randint(0, 256, (num_centers, 3))\n",
    "\n",
    "            y, x = np.mgrid[0:CFG.IMG_SIZE, 0:CFG.IMG_SIZE]\n",
    "\n",
    "            # Calculate distances to each center\n",
    "            distances = np.zeros((num_centers, CFG.IMG_SIZE, CFG.IMG_SIZE))\n",
    "            for i in range(num_centers):\n",
    "                distances[i] = np.sqrt((x - centers[i, 0])**2 + (y - centers[i, 1])**2)\n",
    "\n",
    "            # Find closest center\n",
    "            closest = np.argmin(distances, axis=0)\n",
    "\n",
    "            # Assign colors\n",
    "            for i in range(num_centers):\n",
    "                mask = (closest == i)\n",
    "                img[mask] = colors[i]\n",
    "\n",
    "    return img\n",
    "\n",
    "def create_triangle(triangle_type='random'):\n",
    "    \"\"\"Generate random triangle coordinates based on type\"\"\"\n",
    "    if triangle_type == 'random':\n",
    "        triangle_type = np.random.choice(CFG.TRIANGLE_TYPES)\n",
    "\n",
    "    min_area = CFG.MIN_TRIANGLE_AREA\n",
    "    margin = 10\n",
    "    max_attempts = 100\n",
    "\n",
    "    for _ in range(max_attempts):\n",
    "        size = np.random.randint(50, CFG.IMG_SIZE // 2)\n",
    "        x = np.random.randint(margin, CFG.IMG_SIZE - size - margin)\n",
    "        y = np.random.randint(margin, CFG.IMG_SIZE - size - margin)\n",
    "\n",
    "        if triangle_type == 'regular':\n",
    "            angles = np.sort(np.random.uniform(0, 2*np.pi, 3))\n",
    "            pts = np.array([\n",
    "                [x + int(size * np.cos(a)), y + int(size * np.sin(a))]\n",
    "                for a in angles\n",
    "            ])\n",
    "        elif triangle_type == 'thin':\n",
    "            pts = np.array([\n",
    "                [x, y],\n",
    "                [x + np.random.randint(size//4, size//2), y + size],\n",
    "                [x + np.random.randint(size//2, size), y]\n",
    "            ])\n",
    "        elif triangle_type == 'obtuse':\n",
    "            pts = np.array([\n",
    "                [x, y],\n",
    "                [x + size, y],\n",
    "                [x + np.random.randint(size//4, 3*size//4), y - np.random.randint(size//2, size)]\n",
    "            ])\n",
    "        else:  # right\n",
    "            pts = np.array([\n",
    "                [x, y],\n",
    "                [x + size, y],\n",
    "                [x, y + size]\n",
    "            ])\n",
    "\n",
    "        # Apply random rotation\n",
    "        if np.random.random() < 0.7:\n",
    "            center = tuple(map(int, pts.mean(axis=0)))\n",
    "            rotation_matrix = cv2.getRotationMatrix2D(center, np.random.randint(0, 360), 1.0)\n",
    "            pts = np.hstack((pts, np.ones((3, 1), dtype=np.float32)))\n",
    "            pts = (rotation_matrix @ pts.T).T\n",
    "            pts = np.clip(pts, margin, CFG.IMG_SIZE - margin).astype(int)\n",
    "\n",
    "        # Check if area is sufficient\n",
    "        area = cv2.contourArea(pts)\n",
    "        if area >= min_area:\n",
    "            return pts\n",
    "\n",
    "    # fallback simple triangle\n",
    "    center_x = CFG.IMG_SIZE // 2\n",
    "    center_y = CFG.IMG_SIZE // 2\n",
    "    size = np.random.randint(40, CFG.IMG_SIZE // 3)\n",
    "\n",
    "    return np.array([\n",
    "        [center_x, center_y - size // 2],\n",
    "        [center_x - size // 2, center_y + size // 2],\n",
    "        [center_x + size // 2, center_y + size // 2]\n",
    "    ])\n",
    "\n",
    "def get_triangle_color(background):\n",
    "    \"\"\"Generate a triangle color that contrasts with the background\"\"\"\n",
    "    bg_center = background[background.shape[0]//2, background.shape[1]//2]\n",
    "\n",
    "    # Determine if background is light or dark\n",
    "    is_dark = np.mean(bg_center) < 128\n",
    "\n",
    "    if is_dark:\n",
    "        # Light triangle on dark background\n",
    "        base = np.random.randint(150, 256, 3)\n",
    "    else:\n",
    "        # Dark triangle on light background\n",
    "        base = np.random.randint(0, 100, 3)\n",
    "\n",
    "    # Add some randomness\n",
    "    color = base + np.random.randint(-30, 30, 3)\n",
    "    return np.clip(color, 0, 255).tolist()\n",
    "\n",
    "def draw_triangle_with_effects(img, triangle, color):\n",
    "    \"\"\"Draw a triangle with optional effects for realism\"\"\"\n",
    "    # Create a copy for blending\n",
    "    img_copy = img.copy()\n",
    "\n",
    "    # Fill the triangle\n",
    "    cv2.fillPoly(img_copy, [triangle], color)\n",
    "\n",
    "    # Apply effects\n",
    "    effect = np.random.choice(['none', 'border', 'gradient', 'texture'], p=[0.4, 0.3, 0.2, 0.1])\n",
    "\n",
    "    if effect == 'border':\n",
    "        # Add border\n",
    "        border_color = np.array(color) * 0.7\n",
    "        cv2.polylines(img_copy, [triangle], True, border_color.astype(int).tolist(), thickness=np.random.randint(1, 5))\n",
    "\n",
    "    elif effect == 'gradient':\n",
    "        mask = np.zeros_like(img)\n",
    "        cv2.fillPoly(mask, [triangle], (255, 255, 255))\n",
    "\n",
    "        gradient = np.zeros_like(img)\n",
    "        pt1 = tuple(triangle[0])\n",
    "        pt2 = tuple(triangle[2])\n",
    "        cv2.line(gradient, pt1, pt2, (50, 50, 50), 5)\n",
    "\n",
    "        gradient_strength = np.random.uniform(0.1, 0.3)\n",
    "        img_copy = cv2.addWeighted(img_copy, 1, cv2.bitwise_and(gradient, mask), gradient_strength, 0)\n",
    "\n",
    "    elif effect == 'texture':\n",
    "        # Add texture to triangle\n",
    "        texture_mask = np.zeros((CFG.IMG_SIZE, CFG.IMG_SIZE), dtype=np.uint8)\n",
    "        cv2.fillPoly(texture_mask, [triangle], 255)\n",
    "\n",
    "        # Create noise texture\n",
    "        noise = np.random.randint(0, 50, (CFG.IMG_SIZE, CFG.IMG_SIZE))\n",
    "\n",
    "        # Apply noise where mask is active\n",
    "        for c in range(3):\n",
    "            channel = img_copy[:,:,c]\n",
    "            channel[texture_mask == 255] = np.clip(channel[texture_mask == 255] + noise[texture_mask == 255] - 25, 0, 255)\n",
    "            img_copy[:,:,c] = channel\n",
    "\n",
    "    alpha = np.random.uniform(0.85, 1.0)\n",
    "    img = cv2.addWeighted(img, 1-alpha, img_copy, alpha, 0)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "e7c7a828e1994ea69ec3c61163bfe1cc",
      "5f2bf8b3a4e84c4ebbe365bd38111042",
      "5bd35786c47541af8916b3425db86b96",
      "c5d7f0830e914df09f73fc1a31f6159c",
      "7f9b06d2e8f04c6a975630d15ccadf9b",
      "85b66a980c7948c586ac62268014bacd",
      "c8ee85a34e5345248aa0a747b46063d7",
      "0de52409a6f44a1baaa5e911537c3c39",
      "dcf8743f59be42cb823fafbc383e327f",
      "2e597bb534434533a3e4b525caccef82",
      "b69c407192bd4a52b7cdced0a205d9c1"
     ]
    },
    "id": "dgaXs0BHTfci",
    "outputId": "088fa5cb-8dc3-44f9-c3d2-9bfd5e5dffac"
   },
   "outputs": [],
   "source": [
    "# %% Enhanced Dataset Generation Pipeline\n",
    "def generate_dataset():\n",
    "    \"\"\"Main dataset generation function with progress tracking and error handling\"\"\"\n",
    "    print(\"Generating dataset...\")\n",
    "\n",
    "    triangle_counts = []\n",
    "    triangle_areas = []\n",
    "\n",
    "    for img_num in tqdm(range(CFG.TOTAL_IMAGES)):\n",
    "        try:\n",
    "            img = generate_background()\n",
    "            label_file = os.path.join(CFG.LABEL_DIR, f\"{img_num}.txt\")\n",
    "\n",
    "            if img_num < CFG.TOTAL_IMAGES * CFG.NEGATIVE_RATIO:\n",
    "                num_triangles = 0\n",
    "            else:\n",
    "                weights = [0.5, 0.3, 0.15, 0.05]\n",
    "                num_triangles = np.random.choice(range(1, CFG.MAX_TRIANGLES), p=weights[:CFG.MAX_TRIANGLES-1])\n",
    "\n",
    "            triangle_counts.append(num_triangles)\n",
    "\n",
    "            with open(label_file, 'w') as f:\n",
    "                for _ in range(num_triangles):\n",
    "                    triangle = create_triangle()\n",
    "\n",
    "                    color = get_triangle_color(img)\n",
    "\n",
    "                    img = draw_triangle_with_effects(img, triangle, color)\n",
    "\n",
    "                    area = cv2.contourArea(triangle)\n",
    "                    triangle_areas.append(area)\n",
    "\n",
    "                    x_min, y_min = np.min(triangle, axis=0)\n",
    "                    x_max, y_max = np.max(triangle, axis=0)\n",
    "\n",
    "                    x_center = (x_min + x_max) / (2 * CFG.IMG_SIZE)\n",
    "                    y_center = (y_min + y_max) / (2 * CFG.IMG_SIZE)\n",
    "                    width = (x_max - x_min) / CFG.IMG_SIZE\n",
    "                    height = (y_max - y_min) / CFG.IMG_SIZE\n",
    "\n",
    "                    f.write(f\"0 {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n",
    "\n",
    "            cv2.imwrite(os.path.join(CFG.IMAGE_DIR, f\"{img_num}.jpg\"), img)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating image {img_num}: {e}\")\n",
    "            cv2.imwrite(os.path.join(CFG.IMAGE_DIR, f\"{img_num}.jpg\"),\n",
    "                       np.full((CFG.IMG_SIZE, CFG.IMG_SIZE, 3), 128, dtype=np.uint8))\n",
    "            with open(label_file, 'w') as f:\n",
    "                pass\n",
    "\n",
    "    print(f\"\\nDataset generated with {CFG.TOTAL_IMAGES} images\")\n",
    "    print(f\"Negative samples: {int(CFG.TOTAL_IMAGES * CFG.NEGATIVE_RATIO)} ({CFG.NEGATIVE_RATIO*100:.1f}%)\")\n",
    "    print(f\"Average triangles per positive image: {np.mean(triangle_counts):.2f}\")\n",
    "    if triangle_areas:\n",
    "        print(f\"Average triangle area: {np.mean(triangle_areas):.1f} px²\")\n",
    "        print(f\"Min triangle area: {np.min(triangle_areas):.1f} px²\")\n",
    "        print(f\"Max triangle area: {np.max(triangle_areas):.1f} px²\")\n",
    "\n",
    "start_time = time.time()\n",
    "generate_dataset()\n",
    "print(f\"Dataset generation completed in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "!tree {CFG.BASE_DIR} -L 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tnhMmsKoTkBJ",
    "outputId": "5211b13b-bf1e-4a11-aecb-9e99ecc0e388"
   },
   "outputs": [],
   "source": [
    "# %% Enhanced Dataset Split and Augmentation\n",
    "def prepare_dataset_split():\n",
    "    \"\"\"Split dataset and create data.yaml file\"\"\"\n",
    "    image_files = sorted([f for f in os.listdir(CFG.IMAGE_DIR) if f.endswith('.jpg')])\n",
    "\n",
    "    image_paths = [os.path.abspath(os.path.join(CFG.IMAGE_DIR, f)) for f in image_files]\n",
    "\n",
    "    # Create stratified split based on whether images have triangles or not\n",
    "    has_triangles = []\n",
    "    for img_file in image_files:\n",
    "        label_file = os.path.join(CFG.LABEL_DIR, img_file.replace('.jpg', '.txt'))\n",
    "        has_triangles.append(os.path.getsize(label_file) > 0)\n",
    "\n",
    "    # Split dataset ensuring balanced distribution of positive/negative samples\n",
    "    train_paths, temp_paths = train_test_split(\n",
    "        list(zip(image_paths, has_triangles)),\n",
    "        test_size=CFG.TEST_SIZE + CFG.VAL_SIZE,\n",
    "        stratify=has_triangles,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    train_paths = [path for path, _ in train_paths]\n",
    "    temp_images = [path for path, _ in temp_paths]\n",
    "    temp_has_triangles = [has_triangle for _, has_triangle in temp_paths]\n",
    "\n",
    "    # Further split temp into val and test\n",
    "    val_paths, test_paths = train_test_split(\n",
    "        list(zip(temp_images, temp_has_triangles)),\n",
    "        test_size=CFG.TEST_SIZE / (CFG.TEST_SIZE + CFG.VAL_SIZE),\n",
    "        stratify=temp_has_triangles,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    val_paths = [path for path, _ in val_paths]\n",
    "    test_paths = [path for path, _ in test_paths]\n",
    "\n",
    "    # Write split files\n",
    "    def write_split(file_list, split_name):\n",
    "        with open(f\"{CFG.BASE_DIR}/{split_name}.txt\", 'w') as f:\n",
    "            for file_path in file_list:\n",
    "                f.write(f\"{file_path}\\n\")\n",
    "        return len(file_list)\n",
    "\n",
    "    train_count = write_split(train_paths, 'train')\n",
    "    val_count = write_split(val_paths, 'val')\n",
    "    test_count = write_split(test_paths, 'test')\n",
    "\n",
    "    print(f\"Dataset split: {train_count} train, {val_count} validation, {test_count} test images\")\n",
    "\n",
    "    # Create data.yaml\n",
    "    yaml_content = f\"\"\"train: {os.path.abspath(f'{CFG.BASE_DIR}/train.txt')}\n",
    "val: {os.path.abspath(f'{CFG.BASE_DIR}/val.txt')}\n",
    "test: {os.path.abspath(f'{CFG.BASE_DIR}/test.txt')}\n",
    "\n",
    "nc: 1\n",
    "names: ['triangle']\n",
    "\"\"\"\n",
    "\n",
    "    with open(f\"{CFG.BASE_DIR}/data.yaml\", 'w') as f:\n",
    "        f.write(yaml_content)\n",
    "\n",
    "    print(f\"Created data.yaml at {CFG.BASE_DIR}/data.yaml\")\n",
    "\n",
    "def setup_augmentations():\n",
    "    \"\"\"Define a robust augmentation pipeline for YOLOv8\"\"\"\n",
    "    custom_transform = A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.3),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.ShiftScaleRotate(\n",
    "            shift_limit=0.1,\n",
    "            scale_limit=CFG.AUG_SCALE_LIMIT,\n",
    "            rotate_limit=CFG.AUG_ROTATE_LIMIT,\n",
    "            p=0.5\n",
    "        ),\n",
    "        A.RandomBrightnessContrast(p=0.4),\n",
    "        A.GaussNoise(var_limit=(10, 50), p=0.3),\n",
    "        A.GaussianBlur(blur_limit=(3, 7), p=0.2),\n",
    "        A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.3),\n",
    "    ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n",
    "\n",
    "    return custom_transform\n",
    "\n",
    "prepare_dataset_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q37Gvj-kTnRL",
    "outputId": "133ab4c5-f3d0-4f61-da24-a9026a0a50d8"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "# %% Enhanced YOLOv8 Training Configuration\n",
    "def train_model():\n",
    "    \"\"\"Configure and train YOLOv8 model with optimized parameters\"\"\"\n",
    "    print(\"\\nInitializing YOLOv8 model...\")\n",
    "\n",
    "    os.makedirs(CFG.SAVE_DIR, exist_ok=True)\n",
    "\n",
    "    # Initialize the model\n",
    "    model = YOLO(CFG.MODEL_TYPE)\n",
    "\n",
    "    training_params = {\n",
    "\n",
    "        'data': f\"{CFG.BASE_DIR}/data.yaml\",\n",
    "        'epochs': CFG.EPOCHS,\n",
    "        'batch': CFG.BATCH,\n",
    "        'imgsz': CFG.IMG_SIZE,\n",
    "        'patience': CFG.PATIENCE,\n",
    "        'project': CFG.SAVE_DIR,\n",
    "        'name': 'triangle_detection',\n",
    "        'exist_ok': True,\n",
    "        'pretrained': True,\n",
    "        'optimizer': 'auto',  # AdamW\n",
    "        'workers': CFG.WORKERS,\n",
    "        'seed': 42,\n",
    "        'verbose': True,\n",
    "\n",
    "        'hsv_h': 0.015,\n",
    "        'hsv_s': 0.7,\n",
    "        'hsv_v': 0.4,\n",
    "        'degrees': CFG.AUG_ROTATE_LIMIT,\n",
    "        'translate': 0.1,\n",
    "        'scale': CFG.AUG_SCALE_LIMIT,\n",
    "        'fliplr': 0.5,\n",
    "        'flipud': 0.3,\n",
    "        'mosaic': 0.7,\n",
    "        'mixup': 0.15,\n",
    "\n",
    "        'patience': CFG.PATIENCE,\n",
    "\n",
    "        # Save best model based on validation mAP\n",
    "        'save_period': -1,\n",
    "\n",
    "        'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "        'amp': torch.cuda.is_available(),\n",
    "    }\n",
    "\n",
    "    print(f\"Starting training for {CFG.EPOCHS} epochs...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    results = model.train(**training_params)\n",
    "\n",
    "    training_time = time.time() - start_time\n",
    "    hours, remainder = divmod(training_time, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "\n",
    "    print(f\"Training completed in {int(hours)}h {int(minutes)}m {int(seconds)}s\")\n",
    "\n",
    "    return model, results\n",
    "\n",
    "trained_model, training_results = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lkyD_OhGU9nB"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model):\n",
    "    \"\"\"Comprehensive evaluation of the model\"\"\"\n",
    "    print(\"\\nEvaluating model on test set...\")\n",
    "\n",
    "    metrics = model.val(\n",
    "        data=f\"{CFG.BASE_DIR}/data.yaml\",\n",
    "        split='test',\n",
    "        batch=CFG.BATCH,\n",
    "        imgsz=CFG.IMG_SIZE,\n",
    "        conf=0.25,\n",
    "        iou=0.6,\n",
    "        plots=True\n",
    "    )\n",
    "\n",
    "    print(f\"\"\"\n",
    "{'='*50}\n",
    " Final Evaluation Metrics\n",
    "{'='*50}\n",
    "mAP@50-95: {metrics.box.map.item():.4f}\n",
    "mAP@50: {metrics.box.map50.item():.4f}\n",
    "Precision: {metrics.box.p.item():.4f}\n",
    "Recall: {metrics.box.r.item():.4f}\n",
    "F1 Score: {metrics.box.f1.item():.4f}\n",
    "Inference Speed: {metrics.speed['inference']:.2f}ms/img\n",
    "Average Processing Time: {metrics.speed['preprocess'] + metrics.speed['inference'] + metrics.speed['postprocess']:.2f}ms/img\n",
    "\"\"\")\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "eX_4cgZjTwii",
    "outputId": "4ddd377d-4e3d-438f-8dcf-93fec49270a2"
   },
   "outputs": [],
   "source": [
    "def visualize_results(model, metrics=None):\n",
    "    \"\"\"Create comprehensive visualizations of model performance\"\"\"\n",
    "    if CFG.PLOT_METRICS:\n",
    "        plt.figure(figsize=(20, 12))\n",
    "\n",
    "        # Plot training curves\n",
    "        try:\n",
    "            results_file = f\"{CFG.SAVE_DIR}/triangle_detection/results.csv\"\n",
    "            if os.path.exists(results_file):\n",
    "                import pandas as pd\n",
    "                results_df = pd.read_csv(results_file)\n",
    "\n",
    "                plt.subplot(2, 3, 1)\n",
    "                plt.plot(results_df['epoch'], results_df['metrics/precision(B)'], label='Precision')\n",
    "                plt.plot(results_df['epoch'], results_df['metrics/recall(B)'], label='Recall')\n",
    "                plt.title('Precision & Recall vs Epoch')\n",
    "                plt.xlabel('Epoch')\n",
    "                plt.ylabel('Value')\n",
    "                plt.legend()\n",
    "                plt.grid(True, alpha=0.3)\n",
    "\n",
    "                plt.subplot(2, 3, 2)\n",
    "                plt.plot(results_df['epoch'], results_df['metrics/mAP50(B)'], label='mAP@50')\n",
    "                plt.plot(results_df['epoch'], results_df['metrics/mAP50-95(B)'], label='mAP@50-95')\n",
    "                plt.title('mAP vs Epoch')\n",
    "                plt.xlabel('Epoch')\n",
    "                plt.ylabel('mAP')\n",
    "                plt.legend()\n",
    "                plt.grid(True, alpha=0.3)\n",
    "\n",
    "                plt.subplot(2, 3, 3)\n",
    "                plt.plot(results_df['epoch'], results_df['train/box_loss'], label='Train')\n",
    "                plt.plot(results_df['epoch'], results_df['val/box_loss'], label='Validation')\n",
    "                plt.title('Box Loss vs Epoch')\n",
    "                plt.xlabel('Epoch')\n",
    "                plt.ylabel('Loss')\n",
    "                plt.legend()\n",
    "                plt.grid(True, alpha=0.3)\n",
    "\n",
    "                plt.subplot(2, 3, 4)\n",
    "                plt.plot(results_df['epoch'], results_df['train/cls_loss'], label='Train')\n",
    "                plt.plot(results_df['epoch'], results_df['val/cls_loss'], label='Validation')\n",
    "                plt.title('Classification Loss vs Epoch')\n",
    "                plt.xlabel('Epoch')\n",
    "                plt.ylabel('Loss')\n",
    "                plt.legend()\n",
    "                plt.grid(True, alpha=0.3)\n",
    "\n",
    "                plt.subplot(2, 3, 5)\n",
    "                plt.plot(results_df['epoch'], results_df['train/dfl_loss'], label='Train')\n",
    "                plt.plot(results_df['epoch'], results_df['val/dfl_loss'], label='Validation')\n",
    "                plt.title('DFL Loss vs Epoch')\n",
    "                plt.xlabel('Epoch')\n",
    "                plt.ylabel('Loss')\n",
    "                plt.legend()\n",
    "                plt.grid(True, alpha=0.3)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not plot training curves - {e}\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{CFG.SAVE_DIR}/training_curves.png\")\n",
    "        plt.show()\n",
    "\n",
    "    # Visualize predictions on test samples\n",
    "    test_files = []\n",
    "    with open(f\"{CFG.BASE_DIR}/test.txt\", 'r') as f:\n",
    "        test_files = f.readlines()\n",
    "\n",
    "    test_files = [line.strip() for line in test_files]\n",
    "\n",
    "    if test_files:\n",
    "        num_samples = min(CFG.TEST_SAMPLES, len(test_files))\n",
    "        test_images = np.random.choice(test_files, num_samples, replace=False)\n",
    "\n",
    "        fig, axes = plt.subplots(2, num_samples//2, figsize=(20, 8))\n",
    "        axes = axes.flatten()\n",
    "\n",
    "        for i, (ax, img_path) in enumerate(zip(axes, test_images)):\n",
    "            results = model.predict(img_path, conf=0.25)\n",
    "\n",
    "            plotted = results[0].plot(line_width=2, font_size=14)\n",
    "\n",
    "            ax.imshow(cv2.cvtColor(plotted, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "            num_detections = len(results[0].boxes)\n",
    "            ax.set_title(f\"Sample {i+1}: {num_detections} triangle(s)\")\n",
    "            ax.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{CFG.SAVE_DIR}/prediction_samples.png\")\n",
    "        plt.show()\n",
    "\n",
    "    # Visualize triangle distribution\n",
    "    triangle_counts = []\n",
    "    for img_num in range(CFG.TOTAL_IMAGES):\n",
    "        label_file = os.path.join(CFG.LABEL_DIR, f\"{img_num}.txt\")\n",
    "        if os.path.exists(label_file):\n",
    "            with open(label_file, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                triangle_counts.append(len(lines))\n",
    "\n",
    "    if triangle_counts:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.histplot(triangle_counts, bins=range(max(triangle_counts)+2), kde=False)\n",
    "        plt.title('Distribution of Triangles per Image')\n",
    "        plt.xlabel('Number of Triangles')\n",
    "        plt.ylabel('Count')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        labels = ['No Triangles', '1+ Triangles']\n",
    "        counts = [triangle_counts.count(0), sum(1 for x in triangle_counts if x > 0)]\n",
    "        plt.pie(counts, labels=labels, autopct='%1.1f%%', startangle=90)\n",
    "        plt.title('Positive vs Negative Samples')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{CFG.SAVE_DIR}/dataset_distribution.png\")\n",
    "        plt.show()\n",
    "\n",
    "metrics = evaluate_model(trained_model)\n",
    "visualize_results(trained_model, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b8vvHZYKTyyP"
   },
   "outputs": [],
   "source": [
    "# %% Model Export and Deployment\n",
    "def export_model():\n",
    "    \"\"\"Export the model to ONNX and TorchScript formats\"\"\"\n",
    "    print(\"\\nExporting model...\")\n",
    "\n",
    "    # Path to best model weights\n",
    "    best_weights = f\"{CFG.SAVE_DIR}/triangle_detection/weights/best.pt\"\n",
    "\n",
    "    if os.path.exists(best_weights):\n",
    "        best_model = YOLO(best_weights)\n",
    "\n",
    "        formats = ['onnx', 'torchscript']\n",
    "\n",
    "        for format_type in formats:\n",
    "            try:\n",
    "                export_path = best_model.export(format=format_type)\n",
    "                print(f\"Exported model to {export_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to export to {format_type}: {e}\")\n",
    "\n",
    "        # Copy best model to Drive for safekeeping\n",
    "        save_path = f\"{CFG.SAVE_DIR}/best_triangle_detector.pt\"\n",
    "        shutil.copy(best_weights, save_path)\n",
    "        print(f\"Saved best model to {save_path}\")\n",
    "    else:\n",
    "        print(f\"Warning: Best model weights not found at {best_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E8K0pZQUUAo2",
    "outputId": "620addbe-fb3d-4bab-c48a-6756f3f5523c"
   },
   "outputs": [],
   "source": [
    "# %% Inference Example\n",
    "def inference_demo():\n",
    "    \"\"\"Demonstrate inference on a few test images\"\"\"\n",
    "    print(\"\\nRunning inference demo...\")\n",
    "\n",
    "    # Load best model\n",
    "    best_model_path = f\"{CFG.SAVE_DIR}/triangle_detection/weights/best.pt\"\n",
    "    if not os.path.exists(best_model_path):\n",
    "        print(f\"Model not found at {best_model_path}\")\n",
    "        return\n",
    "\n",
    "    model = YOLO(best_model_path)\n",
    "\n",
    "    with open(f\"{CFG.BASE_DIR}/test.txt\", 'r') as f:\n",
    "        test_files = [line.strip() for line in f.readlines()]\n",
    "\n",
    "    if not test_files:\n",
    "        print(\"No test files found\")\n",
    "        return\n",
    "\n",
    "    # Select a few random test images\n",
    "    sample_size = min(5, len(test_files))\n",
    "    samples = random.sample(test_files, sample_size)\n",
    "\n",
    "    print(\"Running inference on sample images...\")\n",
    "\n",
    "    total_time = 0\n",
    "    total_triangles = 0\n",
    "\n",
    "    for img_path in samples:\n",
    "        start_time = time.time()\n",
    "        results = model.predict(img_path, conf=0.25, verbose=False)\n",
    "        inference_time = time.time() - start_time\n",
    "\n",
    "        total_time += inference_time\n",
    "        num_triangles = len(results[0].boxes)\n",
    "        total_triangles += num_triangles\n",
    "\n",
    "        print(f\"Image: {os.path.basename(img_path)} - Detected {num_triangles} triangles in {inference_time*1000:.1f}ms\")\n",
    "\n",
    "    # Calculate average inference time\n",
    "    avg_time = total_time / sample_size * 1000\n",
    "\n",
    "    print(f\"\\nAverage inference time: {avg_time:.2f}ms per image\")\n",
    "    print(f\"Average triangles detected: {total_triangles/sample_size:.1f}\")\n",
    "    print(f\"FPS: {1000/avg_time:.1f}\")\n",
    "\n",
    "export_model()\n",
    "\n",
    "inference_demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YaxKAAjtUEon"
   },
   "outputs": [],
   "source": [
    "# %% Keep Colab Session Alive\n",
    "def keep_alive():\n",
    "    \"\"\"Colab session keep-alive function\"\"\"\n",
    "    from IPython.display import Javascript\n",
    "    display(Javascript('''\n",
    "    function ClickConnect(){\n",
    "        console.log(\"Keeping session alive\");\n",
    "        document.querySelector(\"colab-connect-button\").click()\n",
    "    }\n",
    "    setInterval(ClickConnect, 60000)\n",
    "    '''))\n",
    "\n",
    "# Uncomment to keep session alive during long runs\n",
    "# keep_alive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uUP3Z8PwVqh4",
    "outputId": "a3f3e571-db44-47af-a285-df36dc75fa03"
   },
   "outputs": [],
   "source": [
    "# %% Summary and Conclusion\n",
    "print(f\"\"\"\n",
    "{'='*70}\n",
    "Triangle Detection Model - Final Summary\n",
    "{'='*70}\n",
    "\n",
    "Dataset:\n",
    "  - Total images: {CFG.TOTAL_IMAGES}\n",
    "  - Positive/negative ratio: {1-CFG.NEGATIVE_RATIO:.1f}/{CFG.NEGATIVE_RATIO:.1f}\n",
    "  - Image size: {CFG.IMG_SIZE}x{CFG.IMG_SIZE}\n",
    "  - Background types: {', '.join(CFG.BG_TYPES)}\n",
    "  - Triangle types: {', '.join(CFG.TRIANGLE_TYPES)}\n",
    "\n",
    "Training:\n",
    "  - Model: YOLOv8 Nano\n",
    "  - Epochs: {CFG.EPOCHS} with patience {CFG.PATIENCE}\n",
    "  - Batch size: {CFG.BATCH}\n",
    "  - Augmentations: Rotation, scaling, flips, color jitter, etc.\n",
    "\n",
    "Results:\n",
    "  - Model saved to: {CFG.SAVE_DIR}/triangle_detection/weights/best.pt\n",
    "  - Exported formats: ONNX, TorchScript\n",
    "\n",
    "Next Steps:\n",
    "  1. For deployment, use the exported models\n",
    "  2. For further improvements:\n",
    "     - Collect real-world triangle images\n",
    "     - Fine-tune on domain-specific data\n",
    "     - Try larger YOLOv8 models (s, m, l) for higher accuracy\n",
    "\n",
    "Thank you for using the Triangle Detection System!\n",
    "{'='*70}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UNHHOG1nS7Mk",
    "outputId": "1d545e8f-f1f4-4845-a24b-99b05548cef4"
   },
   "outputs": [],
   "source": [
    "!pip install nbformat --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nc7IzuuLfPcp"
   },
   "outputs": [],
   "source": [
    "import nbformat\n",
    "from nbformat import read, write, NO_CONVERT\n",
    "\n",
    "# Path to your notebook (change if needed)\n",
    "notebook_path = '/content/your_notebook.ipynb'\n",
    "\n",
    "# Load the notebook\n",
    "with open(notebook_path, 'r', encoding='utf-8') as f:\n",
    "    nb = read(f, as_version=NO_CONVERT)\n",
    "\n",
    "# Clear outputs and fix metadata\n",
    "for cell in nb.cells:\n",
    "    if 'outputs' in cell:\n",
    "        cell['outputs'] = []\n",
    "    if 'execution_count' in cell:\n",
    "        cell['execution_count'] = None\n",
    "    if 'metadata' in cell and 'widgets' in cell['metadata']:\n",
    "        del cell['metadata']['widgets']\n",
    "\n",
    "# Save the cleaned notebook\n",
    "with open(notebook_path, 'w', encoding='utf-8') as f:\n",
    "    write(nb, f)\n",
    "\n",
    "print(\"Notebook cleaned successfully! ✅\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0de52409a6f44a1baaa5e911537c3c39": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e597bb534434533a3e4b525caccef82": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5bd35786c47541af8916b3425db86b96": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0de52409a6f44a1baaa5e911537c3c39",
      "max": 1500,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dcf8743f59be42cb823fafbc383e327f",
      "value": 1500
     }
    },
    "5f2bf8b3a4e84c4ebbe365bd38111042": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_85b66a980c7948c586ac62268014bacd",
      "placeholder": "​",
      "style": "IPY_MODEL_c8ee85a34e5345248aa0a747b46063d7",
      "value": "100%"
     }
    },
    "7f9b06d2e8f04c6a975630d15ccadf9b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "85b66a980c7948c586ac62268014bacd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b69c407192bd4a52b7cdced0a205d9c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c5d7f0830e914df09f73fc1a31f6159c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2e597bb534434533a3e4b525caccef82",
      "placeholder": "​",
      "style": "IPY_MODEL_b69c407192bd4a52b7cdced0a205d9c1",
      "value": " 1500/1500 [00:47&lt;00:00, 33.82it/s]"
     }
    },
    "c8ee85a34e5345248aa0a747b46063d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dcf8743f59be42cb823fafbc383e327f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e7c7a828e1994ea69ec3c61163bfe1cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5f2bf8b3a4e84c4ebbe365bd38111042",
       "IPY_MODEL_5bd35786c47541af8916b3425db86b96",
       "IPY_MODEL_c5d7f0830e914df09f73fc1a31f6159c"
      ],
      "layout": "IPY_MODEL_7f9b06d2e8f04c6a975630d15ccadf9b"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
